{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgbm = df.copy()\n",
    "#Scaling numerical columns\n",
    "scaler = StandardScaler()\n",
    "df_lgbm[df_lgbm._get_numeric_data().columns] = scaler.fit_transform(df_lgbm[df_lgbm._get_numeric_data().columns])  \n",
    "\n",
    "\n",
    "for c in df_lgbm.columns:\n",
    "    col_type = df_lgbm[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        df_lgbm[c] = df_lgbm[c].astype('category')\n",
    "\n",
    "x_lgbm = df_lgbm.drop(['_SALE_PRICE_'],axis=1)\n",
    "y_lgbm=df_lgbm['_SALE_PRICE_'].astype('int64')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_lgbm, y_lgbm, test_size=0.20, random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.353735\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\tvalid_0's l2: 0.34275\n",
      "[3]\tvalid_0's l2: 0.333135\n",
      "[4]\tvalid_0's l2: 0.325506\n",
      "[5]\tvalid_0's l2: 0.314234\n",
      "[6]\tvalid_0's l2: 0.308454\n",
      "[7]\tvalid_0's l2: 0.302212\n",
      "[8]\tvalid_0's l2: 0.297737\n",
      "[9]\tvalid_0's l2: 0.294335\n",
      "[10]\tvalid_0's l2: 0.291734\n",
      "[11]\tvalid_0's l2: 0.289214\n",
      "[12]\tvalid_0's l2: 0.287503\n",
      "[13]\tvalid_0's l2: 0.285233\n",
      "[14]\tvalid_0's l2: 0.283922\n",
      "[15]\tvalid_0's l2: 0.278911\n",
      "[16]\tvalid_0's l2: 0.277633\n",
      "[17]\tvalid_0's l2: 0.277023\n",
      "[18]\tvalid_0's l2: 0.274567\n",
      "[19]\tvalid_0's l2: 0.272599\n",
      "[20]\tvalid_0's l2: 0.270399\n",
      "[21]\tvalid_0's l2: 0.267639\n",
      "[22]\tvalid_0's l2: 0.265354\n",
      "[23]\tvalid_0's l2: 0.264339\n",
      "[24]\tvalid_0's l2: 0.260994\n",
      "[25]\tvalid_0's l2: 0.260399\n",
      "[26]\tvalid_0's l2: 0.259044\n",
      "[27]\tvalid_0's l2: 0.259355\n",
      "[28]\tvalid_0's l2: 0.258856\n",
      "[29]\tvalid_0's l2: 0.261306\n",
      "[30]\tvalid_0's l2: 0.260185\n",
      "[31]\tvalid_0's l2: 0.259912\n",
      "[32]\tvalid_0's l2: 0.259839\n",
      "[33]\tvalid_0's l2: 0.259951\n",
      "[34]\tvalid_0's l2: 0.258547\n",
      "[35]\tvalid_0's l2: 0.257745\n",
      "[36]\tvalid_0's l2: 0.257751\n",
      "[37]\tvalid_0's l2: 0.257627\n",
      "[38]\tvalid_0's l2: 0.259355\n",
      "[39]\tvalid_0's l2: 0.258915\n",
      "[40]\tvalid_0's l2: 0.258843\n",
      "[41]\tvalid_0's l2: 0.259506\n",
      "[42]\tvalid_0's l2: 0.260205\n",
      "[43]\tvalid_0's l2: 0.261062\n",
      "[44]\tvalid_0's l2: 0.257645\n",
      "[45]\tvalid_0's l2: 0.257269\n",
      "[46]\tvalid_0's l2: 0.254008\n",
      "[47]\tvalid_0's l2: 0.254379\n",
      "[48]\tvalid_0's l2: 0.254149\n",
      "[49]\tvalid_0's l2: 0.252347\n",
      "[50]\tvalid_0's l2: 0.250968\n",
      "[51]\tvalid_0's l2: 0.251798\n",
      "[52]\tvalid_0's l2: 0.25121\n",
      "[53]\tvalid_0's l2: 0.252102\n",
      "[54]\tvalid_0's l2: 0.253004\n",
      "[55]\tvalid_0's l2: 0.252217\n",
      "[56]\tvalid_0's l2: 0.25065\n",
      "[57]\tvalid_0's l2: 0.249327\n",
      "[58]\tvalid_0's l2: 0.248377\n",
      "[59]\tvalid_0's l2: 0.247484\n",
      "[60]\tvalid_0's l2: 0.246568\n",
      "[61]\tvalid_0's l2: 0.245891\n",
      "[62]\tvalid_0's l2: 0.245821\n",
      "[63]\tvalid_0's l2: 0.245411\n",
      "[64]\tvalid_0's l2: 0.245906\n",
      "[65]\tvalid_0's l2: 0.244319\n",
      "[66]\tvalid_0's l2: 0.243687\n",
      "[67]\tvalid_0's l2: 0.243426\n",
      "[68]\tvalid_0's l2: 0.243112\n",
      "[69]\tvalid_0's l2: 0.242753\n",
      "[70]\tvalid_0's l2: 0.24269\n",
      "[71]\tvalid_0's l2: 0.242861\n",
      "[72]\tvalid_0's l2: 0.242876\n",
      "[73]\tvalid_0's l2: 0.241599\n",
      "[74]\tvalid_0's l2: 0.241714\n",
      "[75]\tvalid_0's l2: 0.24147\n",
      "[76]\tvalid_0's l2: 0.240875\n",
      "[77]\tvalid_0's l2: 0.24223\n",
      "[78]\tvalid_0's l2: 0.243501\n",
      "[79]\tvalid_0's l2: 0.244616\n",
      "[80]\tvalid_0's l2: 0.244193\n",
      "[81]\tvalid_0's l2: 0.24384\n",
      "[82]\tvalid_0's l2: 0.243953\n",
      "[83]\tvalid_0's l2: 0.243582\n",
      "[84]\tvalid_0's l2: 0.243981\n",
      "[85]\tvalid_0's l2: 0.244334\n",
      "[86]\tvalid_0's l2: 0.246067\n",
      "[87]\tvalid_0's l2: 0.247835\n",
      "[88]\tvalid_0's l2: 0.250291\n",
      "[89]\tvalid_0's l2: 0.249786\n",
      "[90]\tvalid_0's l2: 0.251723\n",
      "[91]\tvalid_0's l2: 0.253137\n",
      "[92]\tvalid_0's l2: 0.252421\n",
      "[93]\tvalid_0's l2: 0.253577\n",
      "[94]\tvalid_0's l2: 0.254743\n",
      "[95]\tvalid_0's l2: 0.253936\n",
      "[96]\tvalid_0's l2: 0.253417\n",
      "[97]\tvalid_0's l2: 0.253126\n",
      "[98]\tvalid_0's l2: 0.252171\n",
      "[99]\tvalid_0's l2: 0.249965\n",
      "[100]\tvalid_0's l2: 0.249594\n",
      "[101]\tvalid_0's l2: 0.248083\n",
      "[102]\tvalid_0's l2: 0.247308\n",
      "[103]\tvalid_0's l2: 0.246574\n",
      "[104]\tvalid_0's l2: 0.246089\n",
      "[105]\tvalid_0's l2: 0.245482\n",
      "[106]\tvalid_0's l2: 0.243759\n",
      "[107]\tvalid_0's l2: 0.244746\n",
      "[108]\tvalid_0's l2: 0.243534\n",
      "[109]\tvalid_0's l2: 0.244471\n",
      "[110]\tvalid_0's l2: 0.243896\n",
      "[111]\tvalid_0's l2: 0.244367\n",
      "[112]\tvalid_0's l2: 0.244587\n",
      "[113]\tvalid_0's l2: 0.244281\n",
      "[114]\tvalid_0's l2: 0.245258\n",
      "[115]\tvalid_0's l2: 0.245031\n",
      "[116]\tvalid_0's l2: 0.244347\n",
      "[117]\tvalid_0's l2: 0.243812\n",
      "[118]\tvalid_0's l2: 0.244357\n",
      "[119]\tvalid_0's l2: 0.243276\n",
      "[120]\tvalid_0's l2: 0.242648\n",
      "[121]\tvalid_0's l2: 0.243909\n",
      "[122]\tvalid_0's l2: 0.244349\n",
      "[123]\tvalid_0's l2: 0.243659\n",
      "[124]\tvalid_0's l2: 0.242799\n",
      "[125]\tvalid_0's l2: 0.242813\n",
      "[126]\tvalid_0's l2: 0.242575\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's l2: 0.240875\n"
     ]
    }
   ],
   "source": [
    "#Training lgbm\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train,y_train)\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'mse'},\n",
    "    'num_leaves': 10,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=1000,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36482621132010057"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for c in df.columns:\n",
    "    col_type = df[c].dtype\n",
    "    if col_type == 'object' or col_type.name == 'category':\n",
    "        df[c] = le.fit_transform(df[c])\n",
    "\n",
    "df[df._get_numeric_data().columns] = scaler.fit_transform(df[df._get_numeric_data().columns])  \n",
    "\n",
    "x = df.drop(['_SALE_PRICE_'],axis=1)\n",
    "y=df['_SALE_PRICE_'].astype('int64')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=314)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10,random_state=0)\n",
    "clf.fit(x, y)\n",
    "\n",
    "#testing the model\n",
    "predictions = clf.predict(x_test)\n",
    "mean_squared_error(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
