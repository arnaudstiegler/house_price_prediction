{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from uszipcode import SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/rollingsales_bronx.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'BOROUGH', u'NEIGHBORHOOD', u'BUILDING CLASS CATEGORY',\n",
      "       u'TAX CLASS AT PRESENT', u'BLOCK', u'LOT', u'EASE-MENT',\n",
      "       u'BUILDING CLASS AT PRESENT', u'ADDRESS', u'APARTMENT NUMBER',\n",
      "       u'ZIP CODE', u'RESIDENTIAL UNITS', u'COMMERCIAL UNITS', u'TOTAL UNITS',\n",
      "       u'LAND SQUARE FEET', u'GROSS SQUARE FEET', u'YEAR BUILT',\n",
      "       u'TAX CLASS AT TIME OF SALE', u'BUILDING CLASS AT TIME OF SALE',\n",
      "       u' SALE PRICE ', u'SALE DATE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df.columns[df.isna().any()].tolist()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'BOROUGH', u'NEIGHBORHOOD', u'BUILDING_CLASS_CATEGORY',\n",
       "       u'TAX_CLASS_AT_PRESENT', u'BLOCK', u'LOT', u'EASE-MENT',\n",
       "       u'BUILDING_CLASS_AT_PRESENT', u'ADDRESS', u'APARTMENT_NUMBER',\n",
       "       u'ZIP_CODE', u'RESIDENTIAL_UNITS', u'COMMERCIAL_UNITS', u'TOTAL_UNITS',\n",
       "       u'LAND_SQUARE_FEET', u'GROSS_SQUARE_FEET', u'YEAR_BUILT',\n",
       "       u'TAX_CLASS_AT_TIME_OF_SALE', u'BUILDING_CLASS_AT_TIME_OF_SALE',\n",
       "       u'_SALE_PRICE_', u'SALE_DATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropping very sparse columns with potentially little info\n",
    "df = df.drop(['EASE-MENT','APARTMENT_NUMBER'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       17/08/2018\n",
       "1       22/03/2018\n",
       "2       06/11/2017\n",
       "3       05/03/2018\n",
       "4       13/11/2017\n",
       "5       22/02/2018\n",
       "6       15/02/2018\n",
       "7       18/07/2018\n",
       "8       23/02/2018\n",
       "9       22/03/2018\n",
       "10      19/06/2018\n",
       "11      22/08/2018\n",
       "12      20/03/2018\n",
       "13      26/03/2018\n",
       "14      19/01/2018\n",
       "15      28/09/2018\n",
       "16      30/05/2018\n",
       "17      28/06/2018\n",
       "18      05/06/2018\n",
       "19      20/12/2017\n",
       "20      13/11/2017\n",
       "21      23/07/2018\n",
       "22      11/04/2018\n",
       "23      29/08/2018\n",
       "24      28/08/2018\n",
       "25      29/08/2018\n",
       "26      07/08/2018\n",
       "27      03/01/2018\n",
       "28      18/07/2018\n",
       "29      12/04/2018\n",
       "           ...    \n",
       "7620    28/11/2017\n",
       "7621    30/11/2017\n",
       "7622    30/04/2018\n",
       "7623    30/07/2018\n",
       "7624    13/08/2018\n",
       "7625    20/09/2018\n",
       "7626    15/10/2018\n",
       "7627    27/12/2017\n",
       "7628    10/05/2018\n",
       "7629    20/08/2018\n",
       "7630    23/08/2018\n",
       "7631    04/09/2018\n",
       "7632    16/11/2017\n",
       "7633    23/05/2018\n",
       "7634    20/06/2018\n",
       "7635    06/02/2018\n",
       "7636    03/04/2018\n",
       "7637    25/07/2018\n",
       "7638    30/07/2018\n",
       "7639    04/09/2018\n",
       "7640    13/09/2018\n",
       "7641    15/12/2017\n",
       "7642    14/05/2018\n",
       "7643    21/11/2017\n",
       "7644    22/01/2018\n",
       "7645    23/04/2018\n",
       "7646    02/08/2018\n",
       "7647    30/08/2018\n",
       "7648    02/08/2018\n",
       "7649    23/07/2018\n",
       "Name: SALE_DATE, Length: 7650, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SALE_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['SALE_DATE'] = pd.to_datetime(df['SALE_DATE'],format='%d/%m/%Y')\n",
    "df['_SALE_PRICE_'] = df['_SALE_PRICE_'].apply(lambda x:x.replace(' ','').replace('$',''))\n",
    "df['year'] = df['SALE_DATE'].apply(lambda x:x.year)\n",
    "df['month'] = df['SALE_DATE'].apply(lambda x:x.month)\n",
    "df['weekday'] = df['SALE_DATE'].apply(lambda x:x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_df(filename):\n",
    "    \n",
    "    df = pd.read_csv('data/'+filename,sep=';')\n",
    "    df.columns = df.columns.str.replace(' ','_')\n",
    "    #Dropping very sparse columns\n",
    "    df = df.drop(['EASE-MENT','APARTMENT_NUMBER'],axis=1)\n",
    "    \n",
    "    #Dropping houses with missing price\n",
    "    df = df[df['_SALE_PRICE_'] != \" $-   \"]\n",
    "        \n",
    "    #Turn Sale price column in numerical data\n",
    "    df['_SALE_PRICE_'] = df['_SALE_PRICE_'].apply(lambda x:int(x.replace(' ','').replace('$','')))\n",
    "    df['_SALE_PRICE_']=df['_SALE_PRICE_'].astype('int64')\n",
    "    \n",
    "    #Extract year/month/weekday and drop data column\n",
    "    df['SALE_DATE'] = pd.to_datetime(df['SALE_DATE'],format='%d/%m/%Y')\n",
    "    \n",
    "    #We keep year as a numerical feature (maybe not enough data to use as categorical)\n",
    "    df['year'] = df['SALE_DATE'].apply(lambda x:x.year)\n",
    "    \n",
    "    #Month and weekday as categorical\n",
    "    df['month'] = df['SALE_DATE'].apply(lambda x:x.month).astype('category')\n",
    "    df['weekday'] = df['SALE_DATE'].apply(lambda x:x.weekday()).astype('category')\n",
    "    \n",
    "    df['TAX_CLASS_AT_TIME_OF_SALE'] = df['TAX_CLASS_AT_TIME_OF_SALE'].astype('category')\n",
    "    \n",
    "    df = df.drop(['SALE_DATE'],axis=1)\n",
    "    df = df.drop(['ADDRESS'],axis=1)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57685, 20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = clean_df('rollingsales_bronx.csv')\n",
    "df2 = clean_df('rollingsales_brooklyn.csv')\n",
    "df3 = clean_df('rollingsales_manhattan.csv')\n",
    "df4 = clean_df('rollingsales_queens.csv')\n",
    "df5 = clean_df('rollingsales_statenisland.csv')\n",
    "\n",
    "df=pd.concat([df1,df2,df3,df4,df5])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'BOROUGH', u'BLOCK', u'LOT', u'ZIP_CODE', u'RESIDENTIAL_UNITS',\n",
      "       u'COMMERCIAL_UNITS', u'TOTAL_UNITS', u'LAND_SQUARE_FEET',\n",
      "       u'GROSS_SQUARE_FEET', u'YEAR_BUILT', u'_SALE_PRICE_', u'year'],\n",
      "      dtype='object')\n",
      "(57685, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df._get_numeric_data().columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57685, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#600 columns with NaN values in the coordinates features\n",
    "df = df.dropna()\n",
    "df.shape\n",
    "#col = df._get_numeric_data().columns.tolist()\n",
    "#col.remove('_SALE_PRICE_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-07c276fede6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "df[col] = scaler.fit_transform(df[col]) \n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('data/merged_df_base.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
